{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 📊 Data Exploration and Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates comprehensive data exploration and analysis for molecular datasets.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Overview\\n\",\n",
    "    \"\\n\",\n",
    "    \"We'll cover:\\n\",\n",
    "    \"- Loading and inspecting molecular datasets\\n\",\n",
    "    \"- Data quality assessment\\n\",\n",
    "    \"- Molecular property distributions\\n\",\n",
    "    \"- Chemical space visualization\\n\",\n",
    "    \"- Correlation analysis\\n\",\n",
    "    \"- Drug-likeness assessment\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set plotting style\\n\",\n",
    "    \"plt.style.use('default')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add src directory to path\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import our custom modules\\n\",\n",
    "    \"from data_processing import MolecularDataLoader, MolecularPreprocessor, FeatureEnginerator\\n\",\n",
    "    \"from utils import (\\n\",\n",
    "    \"    assess_data_quality, visualize_molecular_dataset, generate_data_report,\\n\",\n",
    "    \"    check_lipinski_rule_of_five, calculate_diversity_metrics\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ All modules imported successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Create Sample Dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's create a sample molecular dataset for exploration.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create sample molecular dataset\\n\",\n",
    "    \"sample_molecules = {\\n\",\n",
    "    \"    'smiles': [\\n\",\n",
    "    \"        \\\"CCO\\\",  # Ethanol\\n\",\n",
    "    \"        \\\"CC(=O)O\\\",  # Acetic acid\\n\",\n",
    "    \"        \\\"c1ccccc1\\\",  # Benzene\\n\",\n",
    "    \"        \\\"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\\\",  # Ibuprofen\\n\",\n",
    "    \"        \\\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\\\",  # Caffeine\\n\",\n",
    "    \"        \\\"CC(C)(C)NCC(C1=CC(=C(C=C1)O)CO)O\\\",  # Salbutamol\\n\",\n",
    "    \"        \\\"CC1=CC=C(C=C1)C(=O)C2=CC=CC=C2\\\",  # Benzophenone\\n\",\n",
    "    \"        \\\"CC(C)C1=CC=C(C=C1)C(C)C(=O)O\\\",  # Ibuprofen (duplicate for testing)\\n\",\n",
    "    \"        \\\"invalid_smiles\\\",  # Invalid SMILES for testing\\n\",\n",
    "    \"        \\\"C1=CC=C(C=C1)N\\\",  # Aniline\\n\",\n",
    "    \"        \\\"CC(=O)NC1=CC=C(C=C1)O\\\",  # Paracetamol\\n\",\n",
    "    \"        \\\"CC1=CC=CC=C1C(=O)O\\\",  # o-Toluic acid\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    'name': [\\n\",\n",
    "    \"        \\\"Ethanol\\\", \\\"Acetic acid\\\", \\\"Benzene\\\", \\\"Ibuprofen\\\", \\\"Caffeine\\\", \\n\",\n",
    "    \"        \\\"Salbutamol\\\", \\\"Benzophenone\\\", \\\"Ibuprofen_dup\\\", \\\"Invalid\\\", \\n\",\n",
    "    \"        \\\"Aniline\\\", \\\"Paracetamol\\\", \\\"o-Toluic acid\\\"\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    'activity': [0, 0, 1, 1, 1, 1, 0, 1, None, 1, 1, 0],\\n\",\n",
    "    \"    'ic50_nm': [10000, 50000, 500, 100, 200, 75, 5000, 100, None, 300, 150, 8000],\\n\",\n",
    "    \"    'solubility': [0.8, 1.2, -2.1, -3.5, -0.5, 0.2, -4.2, -3.5, None, -1.8, -1.2, -2.8],\\n\",\n",
    "    \"    'dataset_source': ['internal', 'internal', 'chembl', 'chembl', 'pubchem', \\n\",\n",
    "    \"                      'pubchem', 'internal', 'chembl', 'internal', 'chembl', \\n\",\n",
    "    \"                      'pubchem', 'internal']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create DataFrame\\n\",\n",
    "    \"df = pd.DataFrame(sample_molecules)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"📊 Created sample dataset with {len(df)} molecules\\\")\\n\",\n",
    "    \"print(f\\\"Columns: {list(df.columns)}\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Quality Assessment\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's perform a comprehensive data quality assessment.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Perform data quality assessment\\n\",\n",
    "    \"print(\\\"🔍 Performing data quality assessment...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"quality_report = assess_data_quality(df, 'smiles')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n📈 Overall Quality Score: {quality_report.get('overall_quality_score', 'N/A'):.1f}/100\\\")\\n\",\n",
    "    \"print(f\\\"📊 Dataset Size: {quality_report.get('dataset_size', 0)} molecules\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display missing data summary\\n\",\n",
    "    \"print(\\\"\\\\n🔍 Missing Data Summary:\\\")\\n\",\n",
    "    \"missing_data = quality_report.get('missing_data', {})\\n\",\n",
    "    \"for col, info in missing_data.items():\\n\",\n",
    "    \"    if info['count'] > 0:\\n\",\n",
    "    \"        print(f\\\"  {col}: {info['count']} missing ({info['percentage']:.1f}%)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display SMILES quality\\n\",\n",
    "    \"smiles_quality = quality_report.get('smiles_quality', {})\\n\",\n",
    "    \"if 'validity_rate' in smiles_quality:\\n\",\n",
    "    \"    print(f\\\"\\\\n🧬 SMILES Quality:\\\")\\n\",\n",
    "    \"    print(f\\\"  Valid SMILES: {smiles_quality['valid_smiles']}/{smiles_quality['total_smiles']}\\\")\\n\",\n",
    "    \"    print(f\\\"  Validity Rate: {smiles_quality['validity_rate']:.1f}%\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display recommendations\\n\",\n",
    "    \"recommendations = quality_report.get('recommendations', [])\\n\",\n",
    "    \"if recommendations:\\n\",\n",
    "    \"    print(\\\"\\\\n💡 Recommendations:\\\")\\n\",\n",
    "    \"    for i, rec in enumerate(recommendations, 1):\\n\",\n",
    "    \"        print(f\\\"  {i}. {rec}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Molecular Data Processing\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's process the molecular data and extract features.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize processors\\n\",\n",
    "    \"preprocessor = MolecularPreprocessor()\\n\",\n",
    "    \"feature_eng = FeatureEnginerator()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Validate and standardize molecules\\n\",\n",
    "    \"print(\\\"🔬 Validating and standardizing molecules...\\\")\\n\",\n",
    "    \"df_processed = preprocessor.validate_molecules(df)\\n\",\n",
    "    \"df_processed = preprocessor.standardize_molecules(df_processed)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract molecular descriptors\\n\",\n",
    "    \"print(\\\"📊 Extracting molecular descriptors...\\\")\\n\",\n",
    "    \"df_processed = feature_eng.extract_molecular_descriptors(df_processed)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display processing results\\n\",\n",
    "    \"valid_count = df_processed['valid'].sum() if 'valid' in df_processed.columns else len(df_processed)\\n\",\n",
    "    \"print(f\\\"✅ Processed {valid_count}/{len(df_processed)} valid molecules\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show available features\\n\",\n",
    "    \"descriptor_cols = [col for col in df_processed.columns if col not in df.columns]\\n\",\n",
    "    \"if descriptor_cols:\\n\",\n",
    "    \"    print(f\\\"🧪 Extracted {len(descriptor_cols)} molecular descriptors\\\")\\n\",\n",
    "    \"    print(f\\\"New features: {descriptor_cols[:5]}{'...' if len(descriptor_cols) > 5 else ''}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_processed.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Molecular Property Distributions\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's explore the distributions of molecular properties.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot molecular property distributions\\n\",\n",
    "    \"print(\\\"📈 Plotting molecular property distributions...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select properties to plot\\n\",\n",
    "    \"properties_to_plot = ['molecular_weight', 'logp', 'tpsa', 'num_hbd', 'num_hba', 'num_rotatable_bonds']\\n\",\n",
    "    \"available_properties = [prop for prop in properties_to_plot if prop in df_processed.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"if available_properties:\\n\",\n",
    "    \"    # Create subplots\\n\",\n",
    "    \"    n_props = len(available_properties)\\n\",\n",
    "    \"    n_cols = 3\\n\",\n",
    "    \"    n_rows = (n_props + n_cols - 1) // n_cols\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\\n\",\n",
    "    \"    if n_rows == 1:\\n\",\n",
    "    \"        axes = axes.reshape(1, -1)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, prop in enumerate(available_properties):\\n\",\n",
    "    \"        row, col = i // n_cols, i % n_cols\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot histogram\\n\",\n",
    "    \"        data = df_processed[prop].dropna()\\n\",\n",
    "    \"        if len(data) > 0:\\n\",\n",
    "    \"            axes[row, col].hist(data, bins=min(10, len(data)), alpha=0.7, edgecolor='black')\\n\",\n",
    "    \"            axes[row, col].set_title(f'{prop.replace(\\\"_\\\", \\\" \\\").title()} Distribution')\\n\",\n",
    "    \"            axes[row, col].set_xlabel(prop.replace('_', ' ').title())\\n\",\n",
    "    \"            axes[row, col].set_ylabel('Frequency')\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Add statistics\\n\",\n",
    "    \"            mean_val = data.mean()\\n\",\n",
    "    \"            std_val = data.std()\\n\",\n",
    "    \"            axes[row, col].axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\\n\",\n",
    "    \"            axes[row, col].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Hide unused subplots\\n\",\n",
    "    \"    for i in range(len(available_properties), n_rows * n_cols):\\n\",\n",
    "    \"        row, col = i // n_cols, i % n_cols\\n\",\n",
    "    \"        axes[row, col].set_visible(False)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"⚠️  No molecular descriptors available for plotting\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Activity vs Properties Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the relationship between molecular properties and biological activity.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze activity vs properties\\n\",\n",
    "    \"print(\\\"🎯 Analyzing activity vs molecular properties...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Filter valid molecules with activity data\\n\",\n",
    "    \"df_analysis = df_processed[df_processed['activity'].notna()].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(df_analysis) > 0 and available_properties:\\n\",\n",
    "    \"    # Create comparison plots\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 1. Molecular weight vs activity\\n\",\n",
    "    \"    if 'molecular_weight' in df_analysis.columns:\\n\",\n",
    "    \"        active = df_analysis[df_analysis['activity'] == 1]['molecular_weight'].dropna()\\n\",\n",
    "    \"        inactive = df_analysis[df_analysis['activity'] == 0]['molecular_weight'].dropna()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        axes[0, 0].hist([inactive, active], bins=8, alpha=0.7, label=['Inactive', 'Active'], color=['red', 'green'])\\n\",\n",
    "    \"        axes[0, 0].set_title('Molecular Weight Distribution by Activity')\\n\",\n",
    "    \"        axes[0, 0].set_xlabel('Molecular Weight (Da)')\\n\",\n",
    "    \"        axes[0, 0].set_ylabel('Frequency')\\n\",\n",
    "    \"        axes[0, 0].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 2. LogP vs activity\\n\",\n",
    "    \"    if 'logp' in df_analysis.columns:\\n\",\n",
    "    \"        active = df_analysis[df_analysis['activity'] == 1]['logp'].dropna()\\n\",\n",
    "    \"        inactive = df_analysis[df_analysis['activity'] == 0]['logp'].dropna()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        axes[0, 1].hist([inactive, active], bins=8, alpha=0.7, label=['Inactive', 'Active'], color=['red', 'green'])\\n\",\n",
    "    \"        axes[0, 1].set_title('LogP Distribution by Activity')\\n\",\n",
    "    \"        axes[0, 1].set_xlabel('LogP')\\n\",\n",
    "    \"        axes[0, 1].set_ylabel('Frequency')\\n\",\n",
    "    \"        axes[0, 1].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 3. IC50 distribution\\n\",\n",
    "    \"    ic50_data = df_analysis['ic50_nm'].dropna()\\n\",\n",
    "    \"    if len(ic50_data) > 0:\\n\",\n",
    "    \"        axes[1, 0].hist(np.log10(ic50_data), bins=8, alpha=0.7, color='blue')\\n\",\n",
    "    \"        axes[1, 0].set_title('IC50 Distribution (log scale)')\\n\",\n",
    "    \"        axes[1, 0].set_xlabel('log10(IC50 nM)')\\n\",\n",
    "    \"        axes[1, 0].set_ylabel('Frequency')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 4. Solubility vs activity\\n\",\n",
    "    \"    solubility_data = df_analysis['solubility'].dropna()\\n\",\n",
    "    \"    if len(solubility_data) > 0:\\n\",\n",
    "    \"        active_sol = df_analysis[df_analysis['activity'] == 1]['solubility'].dropna()\\n\",\n",
    "    \"        inactive_sol = df_analysis[df_analysis['activity'] == 0]['solubility'].dropna()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        axes[1, 1].hist([inactive_sol, active_sol], bins=8, alpha=0.7, \\n\",\n",
    "    \"                       label=['Inactive', 'Active'], color=['red', 'green'])\\n\",\n",
    "    \"        axes[1, 1].set_title('Solubility Distribution by Activity')\\n\",\n",
    "    \"        axes[1, 1].set_xlabel('Solubility (log units)')\\n\",\n",
    "    \"        axes[1, 1].set_ylabel('Frequency')\\n\",\n",
    "    \"        axes[1, 1].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate summary statistics\\n\",\n",
    "    \"    print(\\\"\\\\n📊 Summary Statistics by Activity:\\\")\\n\",\n",
    "    \"    for activity in [0, 1]:\\n\",\n",
    "    \"        subset = df_analysis[df_analysis['activity'] == activity]\\n\",\n",
    "    \"        activity_label = \\\"Active\\\" if activity == 1 else \\\"Inactive\\\"\\n\",\n",
    "    \"        print(f\\\"\\\\n{activity_label} compounds (n={len(subset)}):\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        for prop in ['molecular_weight', 'logp', 'ic50_nm', 'solubility']:\\n\",\n",
    "    \"            if prop in subset.columns:\\n\",\n",
    "    \"                data = subset[prop].dropna()\\n\",\n",
    "    \"                if len(data) > 0:\\n\",\n",
    "    \"                    print(f\\\"  {prop}: {data.mean():.2f} ± {data.std():.2f}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"⚠️  Insufficient data for activity analysis\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Drug-likeness Assessment\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's assess the drug-likeness of our molecules using Lipinski's Rule of Five.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Assess drug-likeness\\n\",\n",
    "    \"print(\\\"💊 Assessing drug-likeness (Lipinski's Rule of Five)...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"lipinski_results = []\\n\",\n",
    "    \"valid_smiles = df_processed[df_processed.get('valid', True) == True]['smiles'].dropna()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for idx, smiles in enumerate(valid_smiles):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        result = check_lipinski_rule_of_five(smiles)\\n\",\n",
    "    \"        if result.get('valid', False):\\n\",\n",
    "    \"            lipinski_results.append({\\n\",\n",
    "    \"                'SMILES': smiles,\\n\",\n",
    "    \"                'Name': df_processed.iloc[idx].get('name', f'Compound_{idx}'),\\n\",\n",
    "    \"                'MW': result.get('molecular_weight', 0),\\n\",\n",
    "    \"                'LogP': result.get('logp', 0),\\n\",\n",
    "    \"                'HBD': result.get('num_hbd', 0),\\n\",\n",
    "    \"                'HBA': result.get('num_hba', 0),\\n\",\n",
    "    \"                'Violations': result.get('violations', 0),\\n\",\n",
    "    \"                'Drug-like': result.get('drug_like', False)\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"⚠️  Error assessing {smiles}: {e}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if lipinski_results:\\n\",\n",
    "    \"    lipinski_df = pd.DataFrame(lipinski_results)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n📋 Lipinski Assessment Results ({len(lipinski_df)} compounds):\\\")\\n\",\n",
    "    \"    print(lipinski_df.round(2))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Summary statistics\\n\",\n",
    "    \"    drug_like_count = lipinski_df['Drug-like'].sum()\\n\",\n",
    "    \"    print(f\\\"\\\\n📊 Drug-likeness Summary:\\\")\\n\",\n",
    "    \"    print(f\\\"  Drug-like compounds: {drug_like_count}/{len(lipinski_df)} ({drug_like_count/len(lipinski_df)*100:.1f}%)\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Violation distribution\\n\",\n",
    "    \"    violation_counts = lipinski_df['Violations'].value_counts().sort_index()\\n\",\n",
    "    \"    print(f\\\"\\\\n🚫 Violation Distribution:\\\")\\n\",\n",
    "    \"    for violations, count in violation_counts.items():\\n\",\n",
    "    \"        print(f\\\"  {violations} violations: {count} compounds\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot violation distribution\\n\",\n",
    "    \"    plt.figure(figsize=(8, 5))\\n\",\n",
    "    \"    violation_counts.plot(kind='bar', color='skyblue', edgecolor='black')\\n\",\n",
    "    \"    plt.title('Distribution of Lipinski Rule Violations')\\n\",\n",
    "    \"    plt.xlabel('Number of Violations')\\n\",\n",
    "    \"    plt.ylabel('Number of Compounds')\\n\",\n",
    "    \"    plt.xticks(rotation=0)\\n\",\n",
    "    \"    plt.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"⚠️  No valid compounds for Lipinski assessment\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Chemical Diversity Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the chemical diversity of our dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze chemical diversity\\n\",\n",
    "    \"print(\\\"🌈 Analyzing chemical diversity...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"valid_smiles_list = df_processed[df_processed.get('valid', True) == True]['smiles'].dropna().tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(valid_smiles_list) > 1:\\n\",\n",
    "    \"    diversity_metrics = calculate_diversity_metrics(valid_smiles_list)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if 'error' not in diversity_metrics:\\n\",\n",
    "    \"        print(f\\\"\\\\n📊 Diversity Metrics:\\\")\\n\",\n",
    "    \"        print(f\\\"  Number of molecules: {diversity_metrics['num_molecules']}\\\")\\n\",\n",
    "    \"        print(f\\\"  Mean similarity: {diversity_metrics['mean_similarity']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"  Diversity score: {diversity_metrics['diversity_score']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"  Similarity range: {diversity_metrics['min_similarity']:.3f} - {diversity_metrics['max_similarity']:.3f}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Interpret diversity score\\n\",\n",
    "    \"        diversity_score = diversity_metrics['diversity_score']\\n\",\n",
    "    \"        if diversity_score > 0.8:\\n\",\n",
    "    \"            interpretation = \\\"Very diverse dataset\\\"\\n\",\n",
    "    \"        elif diversity_score > 0.6:\\n\",\n",
    "    \"            interpretation = \\\"Moderately diverse dataset\\\"\\n\",\n",
    "    \"        elif diversity_score > 0.4:\\n\",\n",
    "    \"            interpretation = \\\"Low diversity dataset\\\"\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            interpretation = \\\"Very low diversity dataset\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"\\\\n💡 Interpretation: {interpretation}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"⚠️  Error calculating diversity: {diversity_metrics['error']}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"⚠️  Insufficient valid molecules for diversity analysis\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Correlation Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's examine correlations between molecular properties and biological endpoints.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Correlation analysis\\n\",\n",
    "    \"print(\\\"🔗 Performing correlation analysis...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select numeric columns for correlation\\n\",\n",
    "    \"numeric_cols = df_processed.select_dtypes(include=[np.number]).columns.tolist()\\n\",\n",
    "    \"correlation_cols = [col for col in numeric_cols if col not in ['valid']]\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(correlation_cols) > 1:\\n\",\n",
    "    \"    # Calculate correlation matrix\\n\",\n",
    "    \"    corr_matrix = df_processed[correlation_cols].corr()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot correlation heatmap\\n\",\n",
    "    \"    plt.figure(figsize=(12, 10))\\n\",\n",
    "    \"    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Mask upper triangle\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\\n\",\n",
    "    \"                square=True, linewidths=0.5, cbar_kws={\\\"shrink\\\": .8}, fmt='.2f')\\n\",\n",
    "    \"    plt.title('Molecular Properties Correlation Matrix')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Find strong correlations\\n\",\n",
    "    \"    print(\\\"\\\\n🔍 Strong Correlations (|r| > 0.7):\\\")\\n\",\n",
    "    \"    strong_corr_found = False\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(len(corr_matrix.columns)):\\n\",\n",
    "    \"        for j in range(i+1, len(corr_matrix.columns)):\\n\",\n",
    "    \"            corr_val = corr_matrix.iloc[i, j]\\n\",\n",
    "    \"            if abs(corr_val) > 0.7 and not np.isnan(corr_val):\\n\",\n",
    "    \"                col1, col2 = corr_matrix.columns[i], corr_matrix.columns[j]\\n\",\n",
    "    \"                print(f\\\"  {col1} - {col2}: {corr_val:.3f}\\\")\\n\",\n",
    "    \"                strong_corr_found = True\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not strong_corr_found:\\n\",\n",
    "    \"        print(\\\"  No strong correlations found\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Activity correlations (if available)\\n\",\n",
    "    \"    if 'activity' in correlation_cols:\\n\",\n",
    "    \"        activity_corr = corr_matrix['activity'].drop('activity').sort_values(key=abs, ascending=False)\\n\",\n",
    "    \"        print(f\\\"\\\\n🎯 Properties most correlated with activity:\\\")\\n\",\n",
    "    \"        for prop, corr_val in activity_corr.head(5).items():\\n\",\n",
    "    \"            if not np.isnan(corr_val):\\n\",\n",
    "    \"                print(f\\\"  {prop}: {corr_val:.3f}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"⚠️  Insufficient numeric columns for correlation analysis\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Dataset Summary and Recommendations\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's generate a comprehensive summary and recommendations.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate comprehensive dataset summary\\n\",\n",
    "    \"print(\\\"📋 Generating dataset summary and recommendations...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"DATASET SUMMARY REPORT\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Basic statistics\\n\",\n",
    "    \"print(f\\\"\\\\n📊 Basic Statistics:\\\")\\n\",\n",
    "    \"print(f\\\"  Total molecules: {len(df)}\\\")\\n\",\n",
    "    \"valid_count = df_processed.get('valid', pd.Series([True]*len(df))).sum()\\n\",\n",
    "    \"print(f\\\"  Valid molecules: {valid_count}\\\")\\n\",\n",
    "    \"print(f\\\"  Columns: {len(df.columns)}\\\")\\n\",\n",
    "    \"print(f\\\"  Data sources: {df['dataset_source'].nunique() if 'dataset_source' in df.columns else 'N/A'}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Activity distribution\\n\",\n",
    "    \"if 'activity' in df.columns:\\n\",\n",
    "    \"    activity_dist = df['activity'].value_counts()\\n\",\n",
    "    \"    print(f\\\"\\\\n🎯 Activity Distribution:\\\")\\n\",\n",
    "    \"    print(f\\\"  Active compounds: {activity_dist.get(1, 0)}\\\")\\n\",\n",
    "    \"    print(f\\\"  Inactive compounds: {activity_dist.get(0, 0)}\\\")\\n\",\n",
    "    \"    print(f\\\"  Missing activity: {df['activity'].isnull().sum()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Property ranges\\n\",\n",
    "    \"if available_properties:\\n\",\n",
    "    \"    print(f\\\"\\\\n🧪 Molecular Property Ranges:\\\")\\n\",\n",
    "    \"    for prop in available_properties[:5]:  # Show first 5 properties\\n\",\n",
    "    \"        if prop in df_processed.columns:\\n\",\n",
    "    \"            data = df_processed[prop].dropna()\\n\",\n",
    "    \"            if len(data) > 0:\\n\",\n",
    "    \"                print(f\\\"  {prop}: {data.min():.2f} - {data.max():.2f} (mean: {data.mean():.2f})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Data quality issues\\n\",\n",
    "    \"print(f\\\"\\\\n⚠️  Data Quality Issues:\\\")\\n\",\n",
    "    \"issues_found = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Missing data\\n\",\n",
    "    \"missing_data = df.isnull().sum()\\n\",\n",
    "    \"for col, missing_count in missing_data.items():\\n\",\n",
    "    \"    if missing_count > 0:\\n\",\n",
    "    \"        print(f\\\"  {col}: {missing_count} missing values ({missing_count/len(df)*100:.1f}%)\\\")\\n\",\n",
    "    \"        issues_found = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Duplicates\\n\",\n",
    "    \"duplicate_count = df.duplicated().sum()\\n\",\n",
    "    \"if duplicate_count > 0:\\n\",\n",
    "    \"    print(f\\\"  Duplicate rows: {duplicate_count}\\\")\\n\",\n",
    "    \"    issues_found = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not issues_found:\\n\",\n",
    "    \"    print(\\\"  No major data quality issues detected\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Recommendations\\n\",\n",
    "    \"print(f\\\"\\\\n💡 Recommendations:\\\")\\n\",\n",
    "    \"recommendations = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Data quality recommendations\\n\",\n",
    "    \"if df['activity'].isnull().sum() > 0:\\n\",\n",
    "    \"    recommendations.append(\\\"Remove or impute missing activity values\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if duplicate_count > 0:\\n\",\n",
    "    \"    recommendations.append(\\\"Remove duplicate entries\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Dataset balance\\n\",\n",
    "    \"if 'activity' in df.columns:\\n\",\n",
    "    \"    activity_counts = df['activity'].value_counts()\\n\",\n",
    "    \"    if len(activity_counts) == 2:\\n\",\n",
    "    \"        ratio = activity_counts.min() / activity_counts.max()\\n\",\n",
    "    \"        if ratio < 0.3:\\n\",\n",
    "    \"            recommendations.append(\\\"Dataset is imbalanced - consider balancing techniques\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sample size\\n\",\n",
    "    \"if len(df) < 100:\\n\",\n",
    "    \"    recommendations.append(\\\"Small dataset - consider collecting more data\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Diversity\\n\",\n",
    "    \"if 'diversity_score' in locals() and diversity_metrics.get('diversity_score', 0) < 0.5:\\n\",\n",
    "    \"    recommendations.append(\\\"Low chemical diversity - consider adding more diverse compounds\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if recommendations:\\n\",\n",
    "    \"    for i, rec in enumerate(recommendations, 1):\\n\",\n",
    "    \"        print(f\\\"  {i}. {rec}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"  Dataset appears to be in good condition\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n🎉 Data exploration completed successfully!\\\")\\n\",\n",
    "    \"print(f\\\"📁 Consider saving processed data for model training\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Save Processed Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's save the processed data for future use.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save processed data\\n\",\n",
    "    \"output_dir = Path('../data/processed')\\n\",\n",
    "    \"output_dir.mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save main processed dataset\\n\",\n",
    "    \"output_file = output_dir / 'processed_molecules.csv'\\n\",\n",
    "    \"df_processed.to_csv(output_file, index=False)\\n\",\n",
    "    \"print(f\\\"💾 Saved processed data to {output_file}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save Lipinski assessment results\\n\",\n",
    "    \"if 'lipinski_df' in locals() and not lipinski_df.empty:\\n\",\n",
    "    \"    lipinski_file = output_dir / 'lipinski_assessment.csv'\\n\",\n",
    "    \"    lipinski_df.to_csv(lipinski_file, index=False)\\n\",\n",
    "    \"    print(f\\\"💾 Saved Lipinski assessment to {lipinski_file}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save data quality report\\n\",\n",
    "    \"if 'quality_report' in locals():\\n\",\n",
    "    \"    report_text = generate_data_report(df_processed, 'smiles', 'activity')\\n\",\n",
    "    \"    report_file = output_dir / 'data_quality_report.txt'\\n\",\n",
    "    \"    with open(report_file, 'w') as f:\\n\",\n",
    "    \"        f.write(report_text)\\n\",\n",
    "    \"    print(f\\\"📋 Saved data quality report to {report_file}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n✅ All outputs saved to {output_dir}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this notebook, we have:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. ✅ **Created and loaded** a sample molecular dataset\\n\",\n",
    "    \"2. ✅ **Assessed data quality** using comprehensive metrics\\n\",\n",
    "    \"3. ✅ **Processed molecular data** with validation and standardization\\n\",\n",
    "    \"4. ✅ **Extracted molecular features** using RDKit descriptors\\n\",\n",
    "    \"5. ✅ **Analyzed property distributions** and their relationships\\n\",\n",
    "    \"6. ✅ **Assessed drug-likeness** using Lipinski's Rule of Five\\n\",\n",
    "    \"7. ✅ **Evaluated chemical diversity** of the dataset\\n\",\n",
    "    \"8. ✅ **Performed correlation analysis** between properties\\n\",\n",
    "    \"9. ✅ **Generated recommendations** for data improvement\\n\",\n",
    "    \"10. ✅ **Saved processed data** for future use\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Feature Engineering**: Create additional molecular features\\n\",\n",
    "    \"- **Model Training**: Use processed data for ML model development\\n\",\n",
    "    \"- **Data Augmentation**: Add more diverse compounds if needed\\n\",\n",
    "    \"- **Advanced Analysis**: Perform clustering and dimensionality reduction\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 🧬 Happy Drug Discovery! 🧬\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"version\": \"3.10.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ],
   "id": "1d7a09451834815b"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
