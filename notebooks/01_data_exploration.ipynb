{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üìä Molecular Dataset Exploration\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides comprehensive exploratory data analysis (EDA) for molecular datasets.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## üéØ Objectives\\n\",\n",
    "    \"- Load and examine molecular datasets\\n\",\n",
    "    \"- Assess data quality and identify issues\\n\",\n",
    "    \"- Visualize molecular property distributions\\n\",\n",
    "    \"- Analyze structure-activity relationships\\n\",\n",
    "    \"- Generate comprehensive data reports\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add src to path\\n\",\n",
    "    \"sys.path.append(str(Path.cwd().parent / 'src'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import project modules\\n\",\n",
    "    \"from data_processing import MolecularDataLoader, MolecularPreprocessor, FeatureEnginerator\\n\",\n",
    "    \"from utils import (\\n\",\n",
    "    \"    assess_data_quality, generate_data_report, visualize_molecular_dataset,\\n\",\n",
    "    \"    validate_smiles, calculate_molecular_descriptors, check_lipinski_rule_of_five\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ Libraries imported successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìÅ Data Loading\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's start by loading a molecular dataset. We'll use sample data or create synthetic data for demonstration.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize data loader\\n\",\n",
    "    \"loader = MolecularDataLoader()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check if sample data exists\\n\",\n",
    "    \"data_dir = Path.cwd().parent / 'data' / 'raw'\\n\",\n",
    "    \"sample_files = list(data_dir.glob('*.csv'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"if sample_files:\\n\",\n",
    "    \"    # Load the first CSV file found\\n\",\n",
    "    \"    data_file = sample_files[0]\\n\",\n",
    "    \"    print(f\\\"üìÇ Loading data from: {data_file}\\\")\\n\",\n",
    "    \"    df = loader.load_csv_file(str(data_file))\\n\",\n",
    "    \"    print(f\\\"‚úÖ Loaded {len(df)} records\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # Create synthetic data for demonstration\\n\",\n",
    "    \"    print(\\\"üìù Creating synthetic molecular dataset...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Sample molecular data\\n\",\n",
    "    \"    sample_data = {\\n\",\n",
    "    \"        'smiles': [\\n\",\n",
    "    \"            'CCO',  # Ethanol\\n\",\n",
    "    \"            'CC(=O)O',  # Acetic acid\\n\",\n",
    "    \"            'c1ccccc1',  # Benzene\\n\",\n",
    "    \"            'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O',  # Ibuprofen\\n\",\n",
    "    \"            'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',  # Caffeine\\n\",\n",
    "    \"            'CC(C)(C)NCC(C1=CC(=C(C=C1)O)CO)O',  # Salbutamol\\n\",\n",
    "    \"            'CC1=CC=C(C=C1)C(=O)O',  # p-Toluic acid\\n\",\n",
    "    \"            'C1=CC=C(C=C1)C(=O)O',  # Benzoic acid\\n\",\n",
    "    \"            'CC(C)NCC(C1=CC(=C(C=C1)O)CO)O',  # Albuterol\\n\",\n",
    "    \"            'C1CCC(CC1)N',  # Cyclohexylamine\\n\",\n",
    "    \"            'CCN(CC)CC(=O)NC1=C(C=CC(=C1)Cl)Cl',  # Lidocaine\\n\",\n",
    "    \"            'CC(C)C1=CC=C(C=C1)C(C)C(=O)O',  # Ibuprofen (duplicate)\\n\",\n",
    "    \"            'invalid_smiles',  # Invalid SMILES\\n\",\n",
    "    \"            'C1=CC=C2C(=C1)C(=CN2)CC(C(=O)O)N',  # Tryptophan\\n\",\n",
    "    \"            'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O'  # Ibuprofen (another duplicate)\\n\",\n",
    "    \"        ],\\n\",\n",
    "    \"        'name': [\\n\",\n",
    "    \"            'Ethanol', 'Acetic acid', 'Benzene', 'Ibuprofen', 'Caffeine',\\n\",\n",
    "    \"            'Salbutamol', 'p-Toluic acid', 'Benzoic acid', 'Albuterol',\\n\",\n",
    "    \"            'Cyclohexylamine', 'Lidocaine', 'Ibuprofen_dup', 'Invalid',\\n\",\n",
    "    \"            'Tryptophan', 'Ibuprofen_dup2'\\n\",\n",
    "    \"        ],\\n\",\n",
    "    \"        'activity': [0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, None, 1, 1],\\n\",\n",
    "    \"        'ic50_nM': [10000, 50000, 1000, 500, 2000, 750, 25000, 15000, 600, 8000, 300, 500, None, 1200, 500],\\n\",\n",
    "    \"        'solubility': [0.8, 1.2, -0.5, -2.1, -0.3, 0.1, -1.8, -1.2, 0.2, -0.8, -2.5, -2.1, None, -1.5, -2.1]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df = pd.DataFrame(sample_data)\\n\",\n",
    "    \"    print(f\\\"‚úÖ Created dataset with {len(df)} records\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display basic info\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"üìù Columns: {list(df.columns)}\\\")\\n\",\n",
    "    \"print(f\\\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show first few rows\\n\",\n",
    "    \"print(\\\"\\\\nüîç First 5 rows:\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîç Data Quality Assessment\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's perform a comprehensive data quality assessment to identify potential issues.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Assess data quality\\n\",\n",
    "    \"print(\\\"üîç Assessing data quality...\\\")\\n\",\n",
    "    \"quality_report = assess_data_quality(df, 'smiles')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display key quality metrics\\n\",\n",
    "    \"print(f\\\"\\\\nüìä QUALITY ASSESSMENT SUMMARY\\\")\\n\",\n",
    "    \"print(f\\\"{'='*40}\\\")\\n\",\n",
    "    \"print(f\\\"Overall Quality Score: {quality_report.get('overall_quality_score', 'N/A'):.1f}/100\\\")\\n\",\n",
    "    \"print(f\\\"Dataset Size: {quality_report['dataset_size']} records\\\")\\n\",\n",
    "    \"print(f\\\"Number of Columns: {len(quality_report['columns'])}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# SMILES quality\\n\",\n",
    "    \"if 'smiles_quality' in quality_report and 'validity_rate' in quality_report['smiles_quality']:\\n\",\n",
    "    \"    smiles_quality = quality_report['smiles_quality']\\n\",\n",
    "    \"    print(f\\\"\\\\nüß™ SMILES Quality:\\\")\\n\",\n",
    "    \"    print(f\\\"  Valid SMILES: {smiles_quality['valid_smiles']}/{smiles_quality['total_smiles']}\\\")\\n\",\n",
    "    \"    print(f\\\"  Validity Rate: {smiles_quality['validity_rate']:.1f}%\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if smiles_quality['invalid_smiles'] > 0:\\n\",\n",
    "    \"        print(f\\\"  ‚ö†Ô∏è  Invalid SMILES found: {smiles_quality['invalid_smiles']}\\\")\\n\",\n",
    "    \"        if 'invalid_examples' in smiles_quality:\\n\",\n",
    "    \"            print(f\\\"  Examples: {smiles_quality['invalid_examples'][:3]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Missing data\\n\",\n",
    "    \"missing_data = quality_report.get('missing_data', {})\\n\",\n",
    "    \"print(f\\\"\\\\n‚ùå Missing Data:\\\")\\n\",\n",
    "    \"for col, info in missing_data.items():\\n\",\n",
    "    \"    if info['count'] > 0:\\n\",\n",
    "    \"        print(f\\\"  {col}: {info['count']} missing ({info['percentage']:.1f}%)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Duplicates\\n\",\n",
    "    \"duplicates = quality_report.get('duplicates', {})\\n\",\n",
    "    \"print(f\\\"\\\\nüîÑ Duplicates:\\\")\\n\",\n",
    "    \"if duplicates.get('total_duplicate_rows', 0) > 0:\\n\",\n",
    "    \"    print(f\\\"  Total duplicate rows: {duplicates['total_duplicate_rows']}\\\")\\n\",\n",
    "    \"if duplicates.get('duplicate_smiles', 0) > 0:\\n\",\n",
    "    \"    print(f\\\"  Duplicate SMILES: {duplicates['duplicate_smiles']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Recommendations\\n\",\n",
    "    \"recommendations = quality_report.get('recommendations', [])\\n\",\n",
    "    \"if recommendations:\\n\",\n",
    "    \"    print(f\\\"\\\\nüí° Recommendations:\\\")\\n\",\n",
    "    \"    for i, rec in enumerate(recommendations, 1):\\n\",\n",
    "    \"        print(f\\\"  {i}. {rec}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"# Generate and display full report\\n\",\n",
    "    \"full_report = generate_data_report(df, 'smiles')\\n\",\n",
    "    \"print(f\\\"\\\\nüìù Full Quality Report:\\\")\\n\",\n",
    "    \"print(full_report)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üßπ Data Preprocessing\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's clean and preprocess the data to improve quality.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize preprocessor\\n\",\n",
    "    \"preprocessor = MolecularPreprocessor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üßπ Preprocessing molecular data...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 1: Validate SMILES\\n\",\n",
    "    \"print(\\\"\\\\n1Ô∏è‚É£ Validating SMILES...\\\")\\n\",\n",
    "    \"df_processed = preprocessor.validate_molecules(df, 'smiles')\\n\",\n",
    "    \"valid_count = df_processed.get('valid', pd.Series([True]*len(df_processed))).sum()\\n\",\n",
    "    \"print(f\\\"   Valid molecules: {valid_count}/{len(df_processed)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 2: Standardize molecules\\n\",\n",
    "    \"print(\\\"\\\\n2Ô∏è‚É£ Standardizing molecules...\\\")\\n\",\n",
    "    \"df_processed = preprocessor.standardize_molecules(df_processed, 'smiles')\\n\",\n",
    "    \"print(f\\\"   Standardized {len(df_processed)} molecules\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 3: Remove duplicates\\n\",\n",
    "    \"print(\\\"\\\\n3Ô∏è‚É£ Removing duplicates...\\\")\\n\",\n",
    "    \"initial_count = len(df_processed)\\n\",\n",
    "    \"df_processed = preprocessor.remove_duplicates(\\n\",\n",
    "    \"    df_processed, \\n\",\n",
    "    \"    'canonical_smiles' if 'canonical_smiles' in df_processed.columns else 'smiles'\\n\",\n",
    "    \")\\n\",\n",
    "    \"removed_count = initial_count - len(df_processed)\\n\",\n",
    "    \"print(f\\\"   Removed {removed_count} duplicates\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Step 4: Apply quality filters\\n\",\n",
    "    \"print(\\\"\\\\n4Ô∏è‚É£ Applying quality filters...\\\")\\n\",\n",
    "    \"initial_count = len(df_processed)\\n\",\n",
    "    \"df_processed = preprocessor.apply_quality_filters(df_processed)\\n\",\n",
    "    \"removed_count = initial_count - len(df_processed)\\n\",\n",
    "    \"print(f\\\"   Removed {removed_count} molecules by quality filters\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n‚úÖ Preprocessing completed: {len(df_processed)} molecules remaining\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display processed data\\n\",\n",
    "    \"print(\\\"\\\\nüîç Processed data (first 5 rows):\\\")\\n\",\n",
    "    \"df_processed.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üßÆ Feature Extraction\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's extract molecular features for analysis.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize feature extractor\\n\",\n",
    "    \"feature_eng = FeatureEnginerator()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üßÆ Extracting molecular features...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract molecular descriptors\\n\",\n",
    "    \"print(\\\"\\\\n1Ô∏è‚É£ Calculating molecular descriptors...\\\")\\n\",\n",
    "    \"smiles_col = 'canonical_smiles' if 'canonical_smiles' in df_processed.columns else 'smiles'\\n\",\n",
    "    \"df_features = feature_eng.extract_molecular_descriptors(df_processed, smiles_col)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract fingerprints\\n\",\n",
    "    \"print(\\\"\\\\n2Ô∏è‚É£ Calculating molecular fingerprints...\\\")\\n\",\n",
    "    \"df_features = feature_eng.extract_molecular_fingerprints(df_features, smiles_col)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Log feature extraction results\\n\",\n",
    "    \"new_features = [col for col in df_features.columns if col not in df_processed.columns]\\n\",\n",
    "    \"print(f\\\"\\\\n‚úÖ Extracted {len(new_features)} new features\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display feature columns\\n\",\n",
    "    \"print(\\\"\\\\nüìä Available features:\\\")\\n\",\n",
    "    \"feature_cols = [col for col in df_features.columns if col not in ['smiles', 'canonical_smiles', 'name']]\\n\",\n",
    "    \"print(f\\\"Total features: {len(feature_cols)}\\\")\\n\",\n",
    "    \"print(f\\\"Feature categories:\\\")\\n\",\n",
    "    \"descriptor_cols = [col for col in feature_cols if not col.startswith('fp_')]\\n\",\n",
    "    \"fingerprint_cols = [col for col in feature_cols if col.startswith('fp_')]\\n\",\n",
    "    \"print(f\\\"  - Molecular descriptors: {len(descriptor_cols)}\\\")\\n\",\n",
    "    \"print(f\\\"  - Fingerprint bits: {len(fingerprint_cols)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show sample of descriptors\\n\",\n",
    "    \"if descriptor_cols:\\n\",\n",
    "    \"    print(f\\\"\\\\nüîç Sample descriptors:\\\")\\n\",\n",
    "    \"    sample_descriptors = descriptor_cols[:10]\\n\",\n",
    "    \"    display_cols = ['name'] + sample_descriptors\\n\",\n",
    "    \"    print(df_features[display_cols].head())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìä Data Visualization\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's create comprehensive visualizations to understand the data better.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comprehensive dataset visualization\\n\",\n",
    "    \"print(\\\"üìä Creating comprehensive dataset visualization...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Use the visualization function from utils\\n\",\n",
    "    \"target_col = 'activity' if 'activity' in df_features.columns else None\\n\",\n",
    "    \"visualize_molecular_dataset(df_features, 'canonical_smiles', target_col)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üî¨ Molecular Property Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze molecular properties in detail.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze molecular properties\\n\",\n",
    "    \"print(\\\"üî¨ Analyzing molecular properties...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select numeric columns for analysis\\n\",\n",
    "    \"numeric_cols = df_features.select_dtypes(include=[np.number]).columns.tolist()\\n\",\n",
    "    \"descriptor_cols = [col for col in numeric_cols if col not in ['activity', 'ic50_nM', 'solubility']]\\n\",\n",
    "    \"\\n\",\n",
    "    \"if descriptor_cols:\\n\",\n",
    "    \"    # Property distributions\\n\",\n",
    "    \"    print(\\\"\\\\nüìä Property Distributions:\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Select key properties for visualization\\n\",\n",
    "    \"    key_properties = ['molecular_weight', 'logp', 'tpsa', 'num_hbd', 'num_hba', 'num_rotatable_bonds']\\n\",\n",
    "    \"    available_properties = [prop for prop in key_properties if prop in df_features.columns]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if available_properties:\\n\",\n",
    "    \"        n_props = len(available_properties)\\n\",\n",
    "    \"        n_cols = min(3, n_props)\\n\",\n",
    "    \"        n_rows = (n_props + n_cols - 1) // n_cols\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\\n\",\n",
    "    \"        if n_props == 1:\\n\",\n",
    "    \"            axes = [axes]\\n\",\n",
    "    \"        elif n_rows == 1:\\n\",\n",
    "    \"            axes = axes.flatten()\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            axes = axes.flatten()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        for i, prop in enumerate(available_properties):\\n\",\n",
    "    \"            if i < len(axes):\\n\",\n",
    "    \"                data = df_features[prop].dropna()\\n\",\n",
    "    \"                axes[i].hist(data, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\\n\",\n",
    "    \"                axes[i].set_title(f'{prop.replace(\\\"_\\\", \\\" \\\").title()} Distribution')\\n\",\n",
    "    \"                axes[i].set_xlabel(prop.replace('_', ' ').title())\\n\",\n",
    "    \"                axes[i].set_ylabel('Frequency')\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                # Add statistics\\n\",\n",
    "    \"                mean_val = data.mean()\\n\",\n",
    "    \"                std_val = data.std()\\n\",\n",
    "    \"                axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\\n\",\n",
    "    \"                axes[i].legend()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Hide unused subplots\\n\",\n",
    "    \"        for i in range(len(available_properties), len(axes)):\\n\",\n",
    "    \"            axes[i].set_visible(False)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Property statistics\\n\",\n",
    "    \"    print(\\\"\\\\nüìà Property Statistics:\\\")\\n\",\n",
    "    \"    if available_properties:\\n\",\n",
    "    \"        stats_df = df_features[available_properties].describe().round(2)\\n\",\n",
    "    \"        print(stats_df)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Property correlations\\n\",\n",
    "    \"    print(\\\"\\\\nüîó Property Correlations:\\\")\\n\",\n",
    "    \"    if len(available_properties) > 1:\\n\",\n",
    "    \"        corr_matrix = df_features[available_properties].corr()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\\n\",\n",
    "    \"                   square=True, linewidths=0.5, fmt='.2f')\\n\",\n",
    "    \"        plt.title('Molecular Properties Correlation Matrix')\\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Find highly correlated pairs\\n\",\n",
    "    \"        high_corr_pairs = []\\n\",\n",
    "    \"        for i in range(len(corr_matrix.columns)):\\n\",\n",
    "    \"            for j in range(i+1, len(corr_matrix.columns)):\\n\",\n",
    "    \"                corr_val = corr_matrix.iloc[i, j]\\n\",\n",
    "    \"                if abs(corr_val) > 0.7:  # High correlation threshold\\n\",\n",
    "    \"                    high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if high_corr_pairs:\\n\",\n",
    "    \"            print(\\\"\\\\n‚ö° Highly Correlated Property Pairs (|r| > 0.7):\\\")\\n\",\n",
    "    \"            for prop1, prop2, corr_val in high_corr_pairs:\\n\",\n",
    "    \"                print(f\\\"  {prop1} ‚Üî {prop2}: r = {corr_val:.3f}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è  No molecular descriptors found for analysis\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üíä Drug-likeness Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze drug-likeness using Lipinski's Rule of Five and other criteria.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze drug-likeness\\n\",\n",
    "    \"print(\\\"üíä Analyzing drug-likeness...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Apply Lipinski's Rule of Five to each molecule\\n\",\n",
    "    \"smiles_col = 'canonical_smiles' if 'canonical_smiles' in df_features.columns else 'smiles'\\n\",\n",
    "    \"\\n\",\n",
    "    \"if smiles_col in df_features.columns:\\n\",\n",
    "    \"    lipinski_results = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for idx, row in df_features.iterrows():\\n\",\n",
    "    \"        smiles = row[smiles_col]\\n\",\n",
    "    \"        if pd.notna(smiles):\\n\",\n",
    "    \"            result = check_lipinski_rule_of_five(smiles)\\n\",\n",
    "    \"            result['compound_name'] = row.get('name', f'Compound_{idx}')\\n\",\n",
    "    \"            result['smiles'] = smiles\\n\",\n",
    "    \"            lipinski_results.append(result)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if lipinski_results:\\n\",\n",
    "    \"        # Convert to DataFrame\\n\",\n",
    "    \"        lipinski_df = pd.DataFrame(lipinski_results)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Remove invalid results\\n\",\n",
    "    \"        valid_results = lipinski_df[lipinski_df['valid'] == True]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if len(valid_results) > 0:\\n\",\n",
    "    \"            print(f\\\"\\\\nüìä Drug-likeness Summary ({len(valid_results)} compounds):\\\")\\n\",\n",
    "    \"            print(f\\\"{'='*50}\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Overall drug-likeness\\n\",\n",
    "    \"            drug_like_count = valid_results['drug_like'].sum()\\n\",\n",
    "    \"            print(f\\\"Drug-like compounds: {drug_like_count}/{len(valid_results)} ({drug_like_count/len(valid_results)*100:.1f}%)\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Violations distribution\\n\",\n",
    "    \"            violations_dist = valid_results['violations'].value_counts().sort_index()\\n\",\n",
    "    \"            print(f\\\"\\\\n‚ö†Ô∏è  Violations distribution:\\\")\\n\",\n",
    "    \"            for violations, count in violations_dist.items():\\n\",\n",
    "    \"                print(f\\\"  {violations} violations: {count} compounds\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Individual rule compliance\\n\",\n",
    "    \"            print(f\\\"\\\\nüìè Individual rule compliance:\\\")\\n\",\n",
    "    \"            rules = ['mw_ok', 'logp_ok', 'hbd_ok', 'hba_ok']\\n\",\n",
    "    \"            rule_names = ['Molecular Weight ‚â§ 500', 'LogP ‚â§ 5', 'H-bond donors ‚â§ 5', 'H-bond acceptors ‚â§ 10']\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            for rule, rule_name in zip(rules, rule_names):\\n\",\n",
    "    \"                if rule in valid_results.columns:\\n\",\n",
    "    \"                    compliance = valid_results[rule].sum()\\n\",\n",
    "    \"                    print(f\\\"  {rule_name}: {compliance}/{len(valid_results)} ({compliance/len(valid_results)*100:.1f}%)\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Visualize property distributions with Lipinski cutoffs\\n\",\n",
    "    \"            print(f\\\"\\\\nüìä Property distributions with Lipinski cutoffs:\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Molecular weight\\n\",\n",
    "    \"            axes[0, 0].hist(valid_results['molecular_weight'], bins=20, alpha=0.7, color='lightblue', edgecolor='black')\\n\",\n",
    "    \"            axes[0, 0].axvline(500, color='red', linestyle='--', label='Lipinski cutoff (500)')\\n\",\n",
    "    \"            axes[0, 0].set_title('Molecular Weight Distribution')\\n\",\n",
    "    \"            axes[0, 0].set_xlabel('Molecular Weight (Da)')\\n\",\n",
    "    \"            axes[0, 0].set_ylabel('Frequency')\\n\",\n",
    "    \"            axes[0, 0].legend()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # LogP\\n\",\n",
    "    \"            axes[0, 1].hist(valid_results['logp'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\\n\",\n",
    "    \"            axes[0, 1].axvline(5, color='red', linestyle='--', label='Lipinski cutoff (5)')\\n\",\n",
    "    \"            axes[0, 1].set_title('LogP Distribution')\\n\",\n",
    "    \"            axes[0, 1].set_xlabel('LogP')\\n\",\n",
    "    \"            axes[0, 1].set_ylabel('Frequency')\\n\",\n",
    "    \"            axes[0, 1].legend()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # H-bond donors\\n\",\n",
    "    \"            axes[1, 0].hist(valid_results['num_hbd'], bins=range(0, max(valid_results['num_hbd'])+2), \\n\",\n",
    "    \"                           alpha=0.7, color='orange', edgecolor='black')\\n\",\n",
    "    \"            axes[1, 0].axvline(5, color='red', linestyle='--', label='Lipinski cutoff (5)')\\n\",\n",
    "    \"            axes[1, 0].set_title('H-bond Donors Distribution')\\n\",\n",
    "    \"            axes[1, 0].set_xlabel('Number of H-bond Donors')\\n\",\n",
    "    \"            axes[1, 0].set_ylabel('Frequency')\\n\",\n",
    "    \"            axes[1, 0].legend()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # H-bond acceptors\\n\",\n",
    "    \"            axes[1, 1].hist(valid_results['num_hba'], bins=range(0, max(valid_results['num_hba'])+2), \\n\",\n",
    "    \"                           alpha=0.7, color='pink', edgecolor='black')\\n\",\n",
    "    \"            axes[1, 1].axvline(10, color='red', linestyle='--', label='Lipinski cutoff (10)')\\n\",\n",
    "    \"            axes[1, 1].set_title('H-bond Acceptors Distribution')\\n\",\n",
    "    \"            axes[1, 1].set_xlabel('Number of H-bond Acceptors')\\n\",\n",
    "    \"            axes[1, 1].set_ylabel('Frequency')\\n\",\n",
    "    \"            axes[1, 1].legend()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            plt.tight_layout()\\n\",\n",
    "    \"            plt.show()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Show examples of drug-like and non-drug-like compounds\\n\",\n",
    "    \"            print(f\\\"\\\\n‚úÖ Examples of drug-like compounds:\\\")\\n\",\n",
    "    \"            drug_like_examples = valid_results[valid_results['drug_like'] == True]\\n\",\n",
    "    \"            if len(drug_like_examples) > 0:\\n\",\n",
    "    \"                for idx, row in drug_like_examples.head(3).iterrows():\\n\",\n",
    "    \"                    print(f\\\"  {row['compound_name']}: MW={row['molecular_weight']:.1f}, LogP={row['logp']:.1f}, \\\"\\n\",\n",
    "    \"                          f\\\"HBD={row['num_hbd']}, HBA={row['num_hba']}\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            print(f\\\"\\\\n‚ùå Examples of non-drug-like compounds:\\\")\\n\",\n",
    "    \"            non_drug_like_examples = valid_results[valid_results['drug_like'] == False]\\n\",\n",
    "    \"            if len(non_drug_like_examples) > 0:\\n\",\n",
    "    \"                for idx, row in non_drug_like_examples.head(3).iterrows():\\n\",\n",
    "    \"                    print(f\\\"  {row['compound_name']}: MW={row['molecular_weight']:.1f}, LogP={row['logp']:.1f}, \\\"\\n\",\n",
    "    \"                          f\\\"HBD={row['num_hbd']}, HBA={row['num_hba']} ({row['violations']} violations)\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"‚ö†Ô∏è  No valid compounds found for drug-likeness analysis\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"‚ö†Ô∏è  Could not perform drug-likeness analysis\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è  No SMILES column found for drug-likeness analysis\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üéØ Structure-Activity Relationship Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the relationship between molecular structure and biological activity.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze structure-activity relationships\\n\",\n",
    "    \"print(\\\"üéØ Analyzing structure-activity relationships...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check if we have activity data\\n\",\n",
    "    \"activity_cols = ['activity', 'ic50_nM', 'solubility']\\n\",\n",
    "    \"available_targets = [col for col in activity_cols if col in df_features.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"if available_targets:\\n\",\n",
    "    \"    print(f\\\"\\\\nüìä Available target variables: {available_targets}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Select molecular descriptors for analysis\\n\",\n",
    "    \"    descriptor_cols = [col for col in df_features.columns \\n\",\n",
    "    \"                      if col not in ['smiles', 'canonical_smiles', 'name', 'valid'] + activity_cols\\n\",\n",
    "    \"                      and not col.startswith('fp_')]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if descriptor_cols:\\n\",\n",
    "    \"        print(f\\\"\\\\nüî¨ Analyzing {len(descriptor_cols)} molecular descriptors\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # For each target variable\\n\",\n",
    "    \"        for target_col in available_targets:\\n\",\n",
    "    \"            target_data = df_features[target_col].dropna()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if len(target_data) > 0:\\n\",\n",
    "    \"                print(f\\\"\\\\nüìà Analysis for {target_col}:\\\")\\n\",\n",
    "    \"                print(f\\\"   Data points: {len(target_data)}\\\")\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                if target_col == 'activity':\\n\",\n",
    "    \"                    # Binary activity analysis\\n\",\n",
    "    \"                    active_count = target_data.sum()\\n\",\n",
    "    \"                    print(f\\\"   Active compounds: {active_count}/{len(target_data)} ({active_count/len(target_data)*100:.1f}%)\\\")\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"                    # Compare properties between active and inactive compounds\\n\",\n",
    "    \"                    if len(descriptor_cols) > 0:\\n\",\n",
    "    \"                        print(f\\\"\\\\nüîç Property comparison (Active vs Inactive):\\\")\\n\",\n",
    "    \"                        \\n\",\n",
    "    \"                        # Get data for active and inactive compounds\\n\",\n",
    "    \"                        active_data = df_features[df_features[target_col] == 1]\\n\",\n",
    "    \"                        inactive_data = df_features[df_features[target_col] == 0]\\n\",\n",
    "    \"                        \\n\",\n",
    "    \"                        if len(active_data) > 0 and len(inactive_data) > 0:\\n\",\n",
    "    \"                            # Select key properties for comparison\\n\",\n",
    "    \"                            key_props = [col for col in descriptor_cols[:6] if col in df_features.columns]\\n\",\n",
    "    \"                            \\n\",\n",
    "    \"                            comparison_data = []\\n\",\n",
    "    \"                            for prop in key_props:\\n\",\n",
    "    \"                                active_mean = active_data[prop].mean()\\n\",\n",
    "    \"                                inactive_mean = inactive_data[prop].mean()\\n\",\n",
    "    \"                                comparison_data.append({\\n\",\n",
    "    \"                                    'Property': prop,\\n\",\n",
    "    \"                                    'Active_Mean': active_mean,\\n\",\n",
    "    \"                                    'Inactive_Mean': inactive_mean,\\n\",\n",
    "    \"                                    'Difference': active_mean - inactive_mean\\n\",\n",
    "    \"                                })\\n\",\n",
    "    \"                            \\n\",\n",
    "    \"                            comparison_df = pd.DataFrame(comparison_data)\\n\",\n",
    "    \"                            print(comparison_df.round(3))\\n\",\n",
    "    \"                            \\n\",\n",
    "    \"                            # Box plots for key properties\\n\",\n",
    "    \"                            if len(key_props) > 0:\\n\",\n",
    "    \"                                n_props = min(4, len(key_props))\\n\",\n",
    "    \"                                fig, axes = plt.subplots(2, 2, figsize=(12, 10))\\n\",\n",
    "    \"                                axes = axes.flatten()\\n\",\n",
    "    \"                                \\n\",\n",
    "    \"                                for i, prop in enumerate(key_props[:n_props]):\\n\",\n",
    "    \"                                    ax = axes[i]\\n\",\n",
    "    \"                                    \\n\",\n",
    "    \"                                    # Prepare data for box plot\\n\",\n",
    "    \"                                    plot_data = []\\n\",\n",
    "    \"                                    labels = []\\n\",\n",
    "    \"                                    \\n\",\n",
    "    \"                                    if len(inactive_data[prop].dropna()) > 0:\\n\",\n",
    "    \"                                        plot_data.append(inactive_data[prop].dropna().values)\\n\",\n",
    "    \"                                        labels.append('Inactive')\\n\",\n",
    "    \"                                    \\n\",\n",
    "    \"                                    if len(active_data[prop].dropna()) > 0:\\n\",\n",
    "    \"                                        plot_data.append(active_data[prop].dropna().values)\\n\",\n",
    "    \"                                        labels.append('Active')\\n\",\n",
    "    \"                                    \\n\",\n",
    "    \"                                    if plot_data:\\n\",\n",
    "    \"                                        ax.boxplot(plot_data, labels=labels)\\n\",\n",
    "    \"                                        ax.set_title(f'{prop.replace(\\\"_\\\", \\\" \\\").title()}')\\n\",\n",
    "    \"                                        ax.set_ylabel(prop.replace('_', ' '))\\n\",\n",
    "    \"                                \\n\",\n",
    "    \"                                # Hide unused subplots\\n\",\n",
    "    \"                                for i in range(n_props, 4):\\n\",\n",
    "    \"                                    axes[i].set_visible(False)\\n\",\n",
    "    \"                                \\n\",\n",
    "    \"                                plt.suptitle(f'Property Comparison: Active vs Inactive Compounds')\\n\",\n",
    "    \"                                plt.tight_layout()\\n\",\n",
    "    \"                                plt.show()\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                elif target_col in ['ic50_nM', 'solubility']:\\n\",\n",
    "    \"                    # Continuous target analysis\\n\",\n",
    "    \"                    print(f\\\"   Mean {target_col}: {target_data.mean():.3f}\\\")\\n\",\n",
    "    \"                    print(f\\\"   Std {target_col}: {target_data.std():.3f}\\\")\\n\",\n",
    "    \"                    print(f\\\"   Range: {target_data.min():.3f} - {target_data.max():.3f}\\\")\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"                    # Distribution plot\\n\",\n",
    "    \"                    plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"                    plt.subplot(1, 2, 1)\\n\",\n",
    "    \"                    plt.hist(target_data, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\\n\",\n",
    "    \"                    plt.title(f'{target_col} Distribution')\\n\",\n",
    "    \"                    plt.xlabel(target_col)\\n\",\n",
    "    \"                    plt.ylabel('Frequency')\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"                    plt.subplot(1, 2, 2)\\n\",\n",
    "    \"                    plt.boxplot(target_data)\\n\",\n",
    "    \"                    plt.title(f'{target_col} Box Plot')\\n\",\n",
    "    \"                    plt.ylabel(target_col)\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"                    plt.tight_layout()\\n\",\n",
    "    \"                    plt.show()\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"                    # Correlation with molecular descriptors\\n\",\n",
    "    \"                    if len(descriptor_cols) > 0:\\n\",\n",
    "    \"                        print(f\\\"\\\\nüîó Correlation with molecular descriptors:\\\")\\n\",\n",
    "    \"                        \\n\",\n",
    "    \"                        correlations = []\\n\",\n",
    "    \"                        for desc in descriptor_cols:\\n\",\n",
    "    \"                            if desc in df_features.columns:\\n\",\n",
    "    \"                                desc_data = df_features[desc].dropna()\\n\",\n",
    "    \"                                if len(desc_data) > 1:\\n\",\n",
    "    \"                                    # Get matching indices\\n\",\n",
    "    \"                                    common_indices = df_features[target_col].dropna().index.intersection(desc_data.index)\\n\",\n",
    "    \"                                    if len(common_indices) > 1:\\n\",\n",
    "    \"                                        corr = df_features.loc[common_indices, target_col].corr(df_features.loc[common_indices, desc])\\n\",\n",
    "    \"                                        if not np.isnan(corr):\\n\",\n",
    "    \"                                            correlations.append((desc, corr))\\n\",\n",
    "    \"                        \\n\",\n",
    "    \"                        # Sort by absolute correlation\\n\",\n",
    "    \"                        correlations.sort(key=lambda x: abs(x[1]), reverse=True)\\n\",\n",
    "    \"                        \\n\",\n",
    "    \"                        # Show top correlations\\n\",\n",
    "    \"                        print(f\\\"   Top correlations:\\\")\\n\",\n",
    "    \"                        for desc, corr in correlations[:5]:\\n\",\n",
    "    \"                            print(f\\\"     {desc}: r = {corr:.3f}\\\")\\n\",\n",
    "    \"                        \\n\",\n",
    "    \"                        # Plot top correlations\\n\",\n",
    "    \"                        if len(correlations) > 0:\\n\",\n",
    "    \"                            top_corr = correlations[0]\\n\",\n",
    "    \"                            desc_name = top_corr[0]\\n\",\n",
    "    \"                            corr_value = top_corr[1]\\n\",\n",
    "    \"                            \\n\",\n",
    "    \"                            plt.figure(figsize=(8, 6))\\n\",\n",
    "    \"                            plt.scatter(df_features[desc_name], df_features[target_col], alpha=0.6)\\n\",\n",
    "    \"                            plt.xlabel(desc_name.replace('_', ' ').title())\\n\",\n",
    "    \"                            plt.ylabel(target_col)\\n\",\n",
    "    \"                            plt.title(f'{desc_name} vs {target_col} (r = {corr_value:.3f})')\\n\",\n",
    "    \"                            plt.tight_layout()\\n\",\n",
    "    \"                            plt.show()\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"‚ö†Ô∏è  No molecular descriptors found for SAR analysis\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è  No target variables found for structure-activity analysis\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìã Summary and Recommendations\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's summarize our findings and provide recommendations for further analysis.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate summary and recommendations\\n\",\n",
    "    \"print(\\\"üìã DATA EXPLORATION SUMMARY\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Dataset summary\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Dataset Overview:\\\")\\n\",\n",
    "    \"print(f\\\"   Original records: {len(df)}\\\")\\n\",\n",
    "    \"print(f\\\"   Processed records: {len(df_processed)}\\\")\\n\",\n",
    "    \"print(f\\\"   Features extracted: {len(df_features.columns)}\\\")\\n\",\n",
    "    \"print(f\\\"   Data quality score: {quality_report.get('overall_quality_score', 'N/A'):.1f}/100\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Key findings\\n\",\n",
    "    \"print(f\\\"\\\\nüîç Key Findings:\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# SMILES quality\\n\",\n",
    "    \"if 'smiles_quality' in quality_report and 'validity_rate' in quality_report['smiles_quality']:\\n\",\n",
    "    \"    validity_rate = quality_report['smiles_quality']['validity_rate']\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ SMILES validity rate: {validity_rate:.1f}%\\\")\\n\",\n",
    "    \"    if validity_rate < 90:\\n\",\n",
    "    \"        print(f\\\"     ‚ö†Ô∏è  Low SMILES validity - consider data cleaning\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Missing data\\n\",\n",
    "    \"missing_data = quality_report.get('missing_data', {})\\n\",\n",
    "    \"high_missing = [col for col, info in missing_data.items() if info['percentage'] > 20]\\n\",\n",
    "    \"if high_missing:\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ High missing data in: {', '.join(high_missing)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Duplicates\\n\",\n",
    "    \"duplicates = quality_report.get('duplicates', {})\\n\",\n",
    "    \"if duplicates.get('duplicate_smiles', 0) > 0:\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Duplicate SMILES found: {duplicates['duplicate_smiles']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature extraction results\\n\",\n",
    "    \"if 'df_features' in locals():\\n\",\n",
    "    \"    descriptor_count = len([col for col in df_features.columns if not col.startswith('fp_') and col not in ['smiles', 'canonical_smiles', 'name', 'valid']])\\n\",\n",
    "    \"    fingerprint_count = len([col for col in df_features.columns if col.startswith('fp_')])\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Molecular descriptors: {descriptor_count}\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Fingerprint features: {fingerprint_count}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Drug-likeness\\n\",\n",
    "    \"if 'lipinski_results' in locals() and lipinski_results:\\n\",\n",
    "    \"    valid_lipinski = [r for r in lipinski_results if r.get('valid', False)]\\n\",\n",
    "    \"    if valid_lipinski:\\n\",\n",
    "    \"        drug_like_count = sum(1 for r in valid_lipinski if r.get('drug_like', False))\\n\",\n",
    "    \"        print(f\\\"   ‚Ä¢ Drug-like compounds: {drug_like_count}/{len(valid_lipinski)} ({drug_like_count/len(valid_lipinski)*100:.1f}%)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Recommendations\\n\",\n",
    "    \"print(f\\\"\\\\nüí° Recommendations:\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Data quality recommendations\\n\",\n",
    "    \"recommendations = quality_report.get('recommendations', [])\\n\",\n",
    "    \"if recommendations:\\n\",\n",
    "    \"    for i, rec in enumerate(recommendations[:3], 1):\\n\",\n",
    "    \"        print(f\\\"   {i}. {rec}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Additional recommendations\\n\",\n",
    "    \"print(f\\\"\\\\nüî¨ Next Steps:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Consider applying feature selection to reduce dimensionality\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Explore advanced molecular descriptors (3D, quantum chemical)\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Implement clustering analysis to identify chemical series\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Consider scaffold-based splitting for model evaluation\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if available_targets:\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Build predictive models for: {', '.join(available_targets)}\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Perform feature importance analysis\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Consider ensemble methods for improved predictions\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n‚úÖ Data exploration completed successfully!\\\")\\n\",\n",
    "    \"print(f\\\"üìù Proceed to feature engineering notebook for advanced analysis.\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ],
   "id": "848946261ead819c"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
